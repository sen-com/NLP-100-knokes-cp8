{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "78. GPU上での学習.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPnEWEd3lBeP9R3mrKdeoY8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sen-com/NLP-100-knokes-cp8/blob/main/78_GPU%E4%B8%8A%E3%81%A7%E3%81%AE%E5%AD%A6%E7%BF%92.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wgo0F4yokdZL",
        "outputId": "0bffdd41-7687-432d-b854-39516d8311db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 問題75のコードを改変し，各エポックのパラメータ更新が完了するたびに，\n",
        "# チェックポイント（学習途中のパラメータ（重み行列など）の値や最適化アルゴリズムの内部状態）をファイルに書き出せ．\n",
        "!nvidia-smi"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Nov 17 12:11:33 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   75C    P0    34W /  70W |   1063MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-UgN3BWkI-y",
        "outputId": "38761574-bfc1-4064-a022-34edaaf0a879",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# データのダウンロード\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00359/NewsAggregatorDataset.zip\n",
        "!unzip NewsAggregatorDataset.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-17 09:40:59--  https://archive.ics.uci.edu/ml/machine-learning-databases/00359/NewsAggregatorDataset.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29224203 (28M) [application/x-httpd-php]\n",
            "Saving to: ‘NewsAggregatorDataset.zip.1’\n",
            "\n",
            "NewsAggregatorDatas 100%[===================>]  27.87M  24.9MB/s    in 1.1s    \n",
            "\n",
            "2020-11-17 09:41:00 (24.9 MB/s) - ‘NewsAggregatorDataset.zip.1’ saved [29224203/29224203]\n",
            "\n",
            "Archive:  NewsAggregatorDataset.zip\n",
            "replace 2pageSessions.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: 2pageSessions.csv       \n",
            "  inflating: __MACOSX/._2pageSessions.csv  \n",
            "  inflating: newsCorpora.csv         \n",
            "  inflating: __MACOSX/._newsCorpora.csv  \n",
            "  inflating: readme.txt              \n",
            "  inflating: __MACOSX/._readme.txt   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKBAlEM1lJKA"
      },
      "source": [
        "# 読込時のエラー回避のためダブルクォーテーションをシングルクォーテーションに置換\n",
        "!sed -e 's/\"/'\\''/g' ./newsCorpora.csv > ./newsCorpora_re.csv"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdectyI3lNpw",
        "outputId": "04b85f57-54f6-457b-9d9e-6f8d7284b706",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# データの読込\n",
        "df = pd.read_csv('./newsCorpora_re.csv', header=None, sep='\\t', names=['ID', 'TITLE', 'URL', 'PUBLISHER', 'CATEGORY', 'STORY', 'HOSTNAME', 'TIMESTAMP'])\n",
        "\n",
        "# データの抽出\n",
        "df = df.loc[df['PUBLISHER'].isin(['Reuters', 'Huffington Post', 'Businessweek', 'Contactmusic.com', 'Daily Mail']), ['TITLE', 'CATEGORY']]\n",
        "\n",
        "# データの分割\n",
        "train, valid_test = train_test_split(df, test_size=0.2, shuffle=True, random_state=123, stratify=df['CATEGORY'])\n",
        "valid, test = train_test_split(valid_test, test_size=0.5, shuffle=True, random_state=123, stratify=valid_test['CATEGORY'])\n",
        "\n",
        "# 事例数の確認\n",
        "print('【学習データ】')\n",
        "print(train['CATEGORY'].value_counts())\n",
        "print('【検証データ】')\n",
        "print(valid['CATEGORY'].value_counts())\n",
        "print('【評価データ】')\n",
        "print(test['CATEGORY'].value_counts())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "【学習データ】\n",
            "b    4501\n",
            "e    4235\n",
            "t    1220\n",
            "m     728\n",
            "Name: CATEGORY, dtype: int64\n",
            "【検証データ】\n",
            "b    563\n",
            "e    529\n",
            "t    153\n",
            "m     91\n",
            "Name: CATEGORY, dtype: int64\n",
            "【評価データ】\n",
            "b    563\n",
            "e    530\n",
            "t    152\n",
            "m     91\n",
            "Name: CATEGORY, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gey3sk3GlXhg"
      },
      "source": [
        "import gdown\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# 学習済み単語ベクトルのダウンロード\n",
        "url = \"https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM\"\n",
        "output = 'GoogleNews-vectors-negative300.bin.gz'\n",
        "gdown.download(url, output, quiet=True)\n",
        "\n",
        "# ダウンロードファイルのロード\n",
        "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nn7dM237mE2g"
      },
      "source": [
        "import string\n",
        "import torch\n",
        "\n",
        "def transform_w2v(text):\n",
        "  table = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
        "  words = text.translate(table).split()  # 記号をスペースに置換後、スペースで分割してリスト化\n",
        "  vec = [model[word] for word in words if word in model]  # 1語ずつベクトル化\n",
        "\n",
        "  return torch.tensor(sum(vec) / len(vec))   # 平均ベクトルをTensor型に変換して出力"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7A951q0nIfi",
        "outputId": "a6abe0cc-72b7-473d-a1a7-1825e2c75cfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 特徴ベクトルの作成\n",
        "X_train = torch.stack([transform_w2v(text) for text in train['TITLE']])\n",
        "X_valid = torch.stack([transform_w2v(text) for text in valid['TITLE']])\n",
        "X_test = torch.stack([transform_w2v(text) for text in test['TITLE']])\n",
        "\n",
        "print(X_train.size())\n",
        "print(X_train)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10684, 300])\n",
            "tensor([[ 0.0837,  0.0056,  0.0068,  ...,  0.0751,  0.0433, -0.0868],\n",
            "        [ 0.0272,  0.0266, -0.0947,  ..., -0.1046, -0.0489, -0.0092],\n",
            "        [ 0.0577, -0.0159, -0.0780,  ..., -0.0421,  0.1229,  0.0876],\n",
            "        ...,\n",
            "        [ 0.0392, -0.0052,  0.0686,  ..., -0.0175,  0.0061, -0.0224],\n",
            "        [ 0.0798,  0.1017,  0.1066,  ..., -0.0752,  0.0623,  0.1138],\n",
            "        [ 0.1664,  0.0451,  0.0508,  ..., -0.0531, -0.0183, -0.0039]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edg4YGt3o_HG",
        "outputId": "bdbadd8c-5eb1-46ef-e2fa-b0bad55ce634",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "category_dict = {'b': 0, 't': 1, 'e':2, 'm':3}\n",
        "train['CATEGORY'].map(lambda x: category_dict[x]).values"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 3, ..., 0, 3, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqK5rMeMncO4",
        "outputId": "eba1e4ca-697b-4fed-fa5b-122b29718585",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# ラベルベクトルの作成\n",
        "category_dict = {'b': 0, 't': 1, 'e':2, 'm':3}\n",
        "y_train = torch.tensor(train['CATEGORY'].map(lambda x: category_dict[x]).values)\n",
        "y_valid = torch.tensor(valid['CATEGORY'].map(lambda x: category_dict[x]).values)\n",
        "y_test = torch.tensor(test['CATEGORY'].map(lambda x: category_dict[x]).values)\n",
        "\n",
        "print(y_train.size())\n",
        "print(y_train)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10684])\n",
            "tensor([0, 1, 3,  ..., 0, 3, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxL5SpcLphLB"
      },
      "source": [
        "# 保存\n",
        "torch.save(X_train, 'X_train.pt')\n",
        "torch.save(X_valid, 'X_valid.pt')\n",
        "torch.save(X_test, 'X_test.pt')\n",
        "torch.save(y_train, 'y_train.pt')\n",
        "torch.save(y_valid, 'y_valid.pt')\n",
        "torch.save(y_test, 'y_test.pt')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv9j53Uxr1FF"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "class SLPNet(nn.Module):\n",
        "  def __init__(self, input_size, output_size):\n",
        "    super().__init__()\n",
        "    self.fc = nn.Linear(input_size, output_size, bias=False)\n",
        "    nn.init.normal_(self.fc.weight, 0.0, 1.0)  # 正規乱数で重みを初期化\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.fc(x)\n",
        "    return x"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Abl6r5Qns27Q",
        "outputId": "3ec235b2-1f28-4134-c192-f2be9270c815",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = SLPNet(300, 4)  # 単層ニューラルネットワークの初期化\n",
        "y_hat_1 = torch.softmax(model(X_train[:1]), dim=-1)\n",
        "print(y_hat_1)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.1466, 0.3975, 0.0425, 0.4134]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReHCUQTVtNs_",
        "outputId": "8f8190b0-a9e4-4135-9cd6-59b1eeffde6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Y_hat = torch.softmax(model.forward(X_train[:4]), dim=-1)\n",
        "print(Y_hat)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.1466, 0.3975, 0.0425, 0.4134],\n",
            "        [0.4738, 0.4325, 0.0456, 0.0481],\n",
            "        [0.2186, 0.5915, 0.0052, 0.1846],\n",
            "        [0.0429, 0.9429, 0.0044, 0.0098]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnDiTD7nvPxP"
      },
      "source": [
        "X_train[:1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpbVjCOtyYCg"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-OBg-oFyZKG",
        "outputId": "88c897f9-13df-4c97-df17-f67b345ed66c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "l_1 = criterion(model(X_train[:1]), y_train[:1])  # 入力ベクトルはsoftmax前の値\n",
        "model.zero_grad()  # 勾配をゼロで初期化\n",
        "l_1.backward()  # 勾配を計算\n",
        "print(f'損失: {l_1:.4f}')\n",
        "print(f'勾配:\\n{model.fc.weight.grad}')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "損失: 1.9200\n",
            "勾配:\n",
            "tensor([[-0.0714, -0.0048, -0.0058,  ..., -0.0641, -0.0370,  0.0741],\n",
            "        [ 0.0333,  0.0022,  0.0027,  ...,  0.0299,  0.0172, -0.0345],\n",
            "        [ 0.0036,  0.0002,  0.0003,  ...,  0.0032,  0.0018, -0.0037],\n",
            "        [ 0.0346,  0.0023,  0.0028,  ...,  0.0311,  0.0179, -0.0359]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5huYG95ylPu",
        "outputId": "d39ede57-9501-4b0c-da01-a0f6501a4619",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "l = criterion(model(X_train[:4]), y_train[:4])\n",
        "model.zero_grad()\n",
        "l.backward()\n",
        "print(f'損失: {l:.4f}')\n",
        "print(f'勾配:\\n{model.fc.weight.grad}')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "損失: 2.4692\n",
            "勾配:\n",
            "tensor([[-0.0121,  0.0016, -0.0163,  ..., -0.0309, -0.0079,  0.0220],\n",
            "        [-0.0001,  0.0061,  0.0172,  ...,  0.0129,  0.0386,  0.0008],\n",
            "        [ 0.0151, -0.0120, -0.0165,  ...,  0.0029, -0.0096,  0.0042],\n",
            "        [-0.0029,  0.0043,  0.0156,  ...,  0.0150, -0.0211, -0.0270]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I-iG0wCy1yY"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class NewsDataset(Dataset):\n",
        "  def __init__(self, X, y):  # datasetの構成要素を指定\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "\n",
        "  def __len__(self):  # len(dataset)で返す値を指定\n",
        "    return len(self.y)\n",
        "\n",
        "  def __getitem__(self, idx):  # dataset[idx]で返す値を指定\n",
        "    return [self.X[idx], self.y[idx]]"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20gWLzGHzIgu"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Datasetの作成\n",
        "dataset_train = NewsDataset(X_train, y_train)\n",
        "dataset_valid = NewsDataset(X_valid, y_valid)\n",
        "dataset_test = NewsDataset(X_test, y_test)\n",
        "\n",
        "# Dataloaderの作成\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=1, shuffle=True)\n",
        "dataloader_valid = DataLoader(dataset_valid, batch_size=len(dataset_valid), shuffle=False)\n",
        "dataloader_test = DataLoader(dataset_test, batch_size=len(dataset_test), shuffle=False)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2xOIV7Fzlim"
      },
      "source": [
        "import time\n",
        "\n",
        "def train_model(dataset_train, dataset_valid, batch_size, model, criterion, optimizer, num_epochs, device):\n",
        "\n",
        "  # GPUに送る\n",
        "  model.to(device)\n",
        "\n",
        "  # dataloaderの作成\n",
        "  dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
        "  dataloader_valid = DataLoader(dataset_valid, batch_size=len(dataset_valid), shuffle=False)\n",
        "\n",
        "  # 学習\n",
        "  log_train = []\n",
        "  log_valid = []\n",
        "  for epoch in range(num_epochs):\n",
        "    # 開始時刻の記録\n",
        "    s_time = time.time()\n",
        "\n",
        "    # 訓練モードに設定\n",
        "    model.train()\n",
        "    for inputs, labels in dataloader_train:\n",
        "      # 勾配をゼロで初期化\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # 順伝播 + 誤差逆伝播 + 重み更新\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    # 損失と正解率の算出\n",
        "    loss_train, acc_train = calculate_loss_and_accuracy(model, criterion, dataloader_train, device)\n",
        "    loss_valid, acc_valid = calculate_loss_and_accuracy(model, criterion, dataloader_valid, device)\n",
        "    log_train.append([loss_train, acc_train])\n",
        "    log_valid.append([loss_valid, acc_valid])\n",
        "\n",
        "    # チェックポイントの保存\n",
        "    torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict()}, f'checkpoint{epoch + 1}.pt')\n",
        "\n",
        "    # 終了時刻の記録\n",
        "    e_time = time.time()\n",
        "\n",
        "    # ログを出力\n",
        "    print(f'epoch: {epoch + 1}, loss_train: {loss_train:.4f}, accuracy_train: {acc_train:.4f}, loss_valid: {loss_valid:.4f}, accuracy_valid: {acc_valid:.4f}, {(e_time - s_time):.4f}sec') \n",
        "\n",
        "  return {'train': log_train, 'valid': log_valid}"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsVAITjX3oaE"
      },
      "source": [
        "def calculate_loss_and_accuracy(model, criterion, loader, device):\n",
        "  model.eval()\n",
        "  loss = 0.0\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in loader:\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = model(inputs)\n",
        "      loss += criterion(outputs, labels).item()\n",
        "      pred = torch.argmax(outputs, dim=-1)\n",
        "      total += len(inputs)\n",
        "      correct += (pred == labels).sum().item()\n",
        "\n",
        "  return loss / len(loader), correct / total"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JEEfCzITuFM",
        "outputId": "ce3067cb-ce8e-4156-ee9c-69b59d58acec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# datasetの作成\n",
        "dataset_train = NewsDataset(X_train, y_train)\n",
        "dataset_valid = NewsDataset(X_valid, y_valid)\n",
        "\n",
        "# モデルの定義\n",
        "model = SLPNet(300, 4)\n",
        "\n",
        "# 損失関数の定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# オプティマイザの定義\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)\n",
        "\n",
        "# デバイスの指定\n",
        "device = torch.device('cuda')\n",
        "\n",
        "# モデルの学習\n",
        "for batch_size in [2 ** i for i in range(11)]:\n",
        "  print(f'バッチサイズ: {batch_size}')\n",
        "  log = train_model(dataset_train, dataset_valid, batch_size, model, criterion, optimizer, 1, device=device)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "バッチサイズ: 1\n",
            "epoch: 1, loss_train: 0.3313, accuracy_train: 0.8829, loss_valid: 0.3640, accuracy_valid: 0.8750, 11.4238sec\n",
            "バッチサイズ: 2\n",
            "epoch: 1, loss_train: 0.3007, accuracy_train: 0.8957, loss_valid: 0.3401, accuracy_valid: 0.8892, 5.7708sec\n",
            "バッチサイズ: 4\n",
            "epoch: 1, loss_train: 0.2910, accuracy_train: 0.9001, loss_valid: 0.3323, accuracy_valid: 0.8885, 2.9800sec\n",
            "バッチサイズ: 8\n",
            "epoch: 1, loss_train: 0.2869, accuracy_train: 0.9013, loss_valid: 0.3301, accuracy_valid: 0.8907, 1.5915sec\n",
            "バッチサイズ: 16\n",
            "epoch: 1, loss_train: 0.2852, accuracy_train: 0.9036, loss_valid: 0.3290, accuracy_valid: 0.8907, 0.8695sec\n",
            "バッチサイズ: 32\n",
            "epoch: 1, loss_train: 0.2842, accuracy_train: 0.9029, loss_valid: 0.3282, accuracy_valid: 0.8907, 0.5385sec\n",
            "バッチサイズ: 64\n",
            "epoch: 1, loss_train: 0.2838, accuracy_train: 0.9030, loss_valid: 0.3280, accuracy_valid: 0.8900, 0.3573sec\n",
            "バッチサイズ: 128\n",
            "epoch: 1, loss_train: 0.2838, accuracy_train: 0.9031, loss_valid: 0.3279, accuracy_valid: 0.8900, 0.2566sec\n",
            "バッチサイズ: 256\n",
            "epoch: 1, loss_train: 0.2832, accuracy_train: 0.9030, loss_valid: 0.3278, accuracy_valid: 0.8907, 0.2203sec\n",
            "バッチサイズ: 512\n",
            "epoch: 1, loss_train: 0.2834, accuracy_train: 0.9030, loss_valid: 0.3278, accuracy_valid: 0.8907, 0.1992sec\n",
            "バッチサイズ: 1024\n",
            "epoch: 1, loss_train: 0.2797, accuracy_train: 0.9031, loss_valid: 0.3277, accuracy_valid: 0.8907, 0.1771sec\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}